{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 3s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# loading the reuters dataset\n",
    "#There are 46 different topics; some topics are more represented than others, but each topic\n",
    "# has at least 10 examples in the trainingset.\n",
    "\n",
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8982"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2246"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 43,\n",
       " 10,\n",
       " 447,\n",
       " 5,\n",
       " 25,\n",
       " 207,\n",
       " 270,\n",
       " 5,\n",
       " 3095,\n",
       " 111,\n",
       " 16,\n",
       " 369,\n",
       " 186,\n",
       " 90,\n",
       " 67,\n",
       " 7,\n",
       " 89,\n",
       " 5,\n",
       " 19,\n",
       " 102,\n",
       " 6,\n",
       " 19,\n",
       " 124,\n",
       " 15,\n",
       " 90,\n",
       " 67,\n",
       " 84,\n",
       " 22,\n",
       " 482,\n",
       " 26,\n",
       " 7,\n",
       " 48,\n",
       " 4,\n",
       " 49,\n",
       " 8,\n",
       " 864,\n",
       " 39,\n",
       " 209,\n",
       " 154,\n",
       " 6,\n",
       " 151,\n",
       " 6,\n",
       " 83,\n",
       " 11,\n",
       " 15,\n",
       " 22,\n",
       " 155,\n",
       " 11,\n",
       " 15,\n",
       " 7,\n",
       " 48,\n",
       " 9,\n",
       " 4579,\n",
       " 1005,\n",
       " 504,\n",
       " 6,\n",
       " 258,\n",
       " 6,\n",
       " 272,\n",
       " 11,\n",
       " 15,\n",
       " 22,\n",
       " 134,\n",
       " 44,\n",
       " 11,\n",
       " 15,\n",
       " 16,\n",
       " 8,\n",
       " 197,\n",
       " 1245,\n",
       " 90,\n",
       " 67,\n",
       " 52,\n",
       " 29,\n",
       " 209,\n",
       " 30,\n",
       " 32,\n",
       " 132,\n",
       " 6,\n",
       " 109,\n",
       " 15,\n",
       " 17,\n",
       " 12]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0] # each example is list of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the data\n",
    "\n",
    "# first vectorizing the data.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "# Our vectorized training data\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# Our vectorized test data\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using one hot encoding then\n",
    "\n",
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "one_hot_test_labels = to_one_hot(test_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building network\n",
    "\n",
    "# here using same 3 layers like before but now instead of 16 hidden units( 16 axes) now using 64 units.\n",
    "\n",
    "# example :\n",
    "# model.add(layers.Dense(64,activation = '' , input_shape=()))\n",
    "\n",
    "# also additional feature is in last layer \n",
    "\n",
    "# model.add(layers.Dense(46,activation = '')) \n",
    "# here for each input , output will have 46 d vector,and with softmax activation it means it will produce a probabity score that will sum upto 1 using 46 output classes.\n",
    "\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model \n",
    "\n",
    "# as optimizer use : rmsprop \n",
    "# loss function : categorical_crossentropy \n",
    "# because it measures distance between 2 probability distributions\n",
    "# i.e between output by network and output by labelled data\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now separating data for validation\n",
    "\n",
    "# setting aside 1000 samples.\n",
    "\n",
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 4s 531us/step - loss: 2.5803 - accuracy: 0.5390 - val_loss: 1.7046 - val_accuracy: 0.6520\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 142us/step - loss: 1.4078 - accuracy: 0.7107 - val_loss: 1.3120 - val_accuracy: 0.7250\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 146us/step - loss: 1.0548 - accuracy: 0.7800 - val_loss: 1.1658 - val_accuracy: 0.7370\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 149us/step - loss: 0.8405 - accuracy: 0.8216 - val_loss: 1.0462 - val_accuracy: 0.7690\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 148us/step - loss: 0.6699 - accuracy: 0.8559 - val_loss: 0.9740 - val_accuracy: 0.8020\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 148us/step - loss: 0.5388 - accuracy: 0.8865 - val_loss: 0.9337 - val_accuracy: 0.8070\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 146us/step - loss: 0.4328 - accuracy: 0.9100 - val_loss: 0.9170 - val_accuracy: 0.8130\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 149us/step - loss: 0.3543 - accuracy: 0.9242 - val_loss: 0.9071 - val_accuracy: 0.8100\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 148us/step - loss: 0.2897 - accuracy: 0.9377 - val_loss: 0.9179 - val_accuracy: 0.8160\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 146us/step - loss: 0.2457 - accuracy: 0.9446 - val_loss: 0.9302 - val_accuracy: 0.8050\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 146us/step - loss: 0.2140 - accuracy: 0.9473 - val_loss: 0.9481 - val_accuracy: 0.8070\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 146us/step - loss: 0.1869 - accuracy: 0.9510 - val_loss: 0.9138 - val_accuracy: 0.8290\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 146us/step - loss: 0.1677 - accuracy: 0.9533 - val_loss: 0.9972 - val_accuracy: 0.8020\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 149us/step - loss: 0.1506 - accuracy: 0.9540 - val_loss: 1.0152 - val_accuracy: 0.8040\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 156us/step - loss: 0.1444 - accuracy: 0.9563 - val_loss: 1.0597 - val_accuracy: 0.7920\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 165us/step - loss: 0.1325 - accuracy: 0.9549 - val_loss: 1.0282 - val_accuracy: 0.8070\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 146us/step - loss: 0.1217 - accuracy: 0.9577 - val_loss: 1.0438 - val_accuracy: 0.8130\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 146us/step - loss: 0.1217 - accuracy: 0.9559 - val_loss: 1.0969 - val_accuracy: 0.7930\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 146us/step - loss: 0.1162 - accuracy: 0.9574 - val_loss: 1.1254 - val_accuracy: 0.7980\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 146us/step - loss: 0.1122 - accuracy: 0.9582 - val_loss: 1.1461 - val_accuracy: 0.7980\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "\n",
    "# 20 epochs\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now displaying it \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now displaying training and validation accuracy \n",
    "plt.clf()\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/12\n",
      "7982/7982 [==============================] - 1s 159us/step - loss: 2.7214 - accuracy: 0.4688 - val_loss: 1.8170 - val_accuracy: 0.6340\n",
      "Epoch 2/12\n",
      "7982/7982 [==============================] - 1s 144us/step - loss: 1.4757 - accuracy: 0.7058 - val_loss: 1.3202 - val_accuracy: 0.7160\n",
      "Epoch 3/12\n",
      "7982/7982 [==============================] - 1s 144us/step - loss: 1.0717 - accuracy: 0.7783 - val_loss: 1.1350 - val_accuracy: 0.7600\n",
      "Epoch 4/12\n",
      "7982/7982 [==============================] - 1s 148us/step - loss: 0.8466 - accuracy: 0.8201 - val_loss: 1.0449 - val_accuracy: 0.7770\n",
      "Epoch 5/12\n",
      "7982/7982 [==============================] - 1s 146us/step - loss: 0.6837 - accuracy: 0.8553 - val_loss: 0.9964 - val_accuracy: 0.7900\n",
      "Epoch 6/12\n",
      "7982/7982 [==============================] - 1s 146us/step - loss: 0.5559 - accuracy: 0.8850 - val_loss: 0.9421 - val_accuracy: 0.8140\n",
      "Epoch 7/12\n",
      "7982/7982 [==============================] - 1s 148us/step - loss: 0.4524 - accuracy: 0.9058 - val_loss: 0.9171 - val_accuracy: 0.8090\n",
      "Epoch 8/12\n",
      "7982/7982 [==============================] - 1s 150us/step - loss: 0.3728 - accuracy: 0.9223 - val_loss: 0.9251 - val_accuracy: 0.8140\n",
      "Epoch 9/12\n",
      "7982/7982 [==============================] - 1s 152us/step - loss: 0.3106 - accuracy: 0.9336 - val_loss: 0.9403 - val_accuracy: 0.8100\n",
      "Epoch 10/12\n",
      "7982/7982 [==============================] - 1s 149us/step - loss: 0.2618 - accuracy: 0.9417 - val_loss: 0.9438 - val_accuracy: 0.8030\n",
      "Epoch 11/12\n",
      "7982/7982 [==============================] - 1s 161us/step - loss: 0.2248 - accuracy: 0.9465 - val_loss: 0.9174 - val_accuracy: 0.8230\n",
      "Epoch 12/12\n",
      "7982/7982 [==============================] - 1s 144us/step - loss: 0.1988 - accuracy: 0.9484 - val_loss: 1.0856 - val_accuracy: 0.7870\n",
      "2246/2246 [==============================] - 0s 221us/step\n"
     ]
    }
   ],
   "source": [
    "# in our case the overfitting begins at around 12-13 epochs\n",
    "\n",
    "# so re training it for 12 epochs\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=12,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1089019242504932, 0.7662510871887207]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/11\n",
      "7982/7982 [==============================] - 1s 154us/step - loss: 2.7194 - accuracy: 0.5148 - val_loss: 1.8035 - val_accuracy: 0.6630\n",
      "Epoch 2/11\n",
      "7982/7982 [==============================] - 1s 142us/step - loss: 1.4753 - accuracy: 0.7055 - val_loss: 1.3348 - val_accuracy: 0.6980\n",
      "Epoch 3/11\n",
      "7982/7982 [==============================] - 1s 142us/step - loss: 1.0788 - accuracy: 0.7711 - val_loss: 1.1297 - val_accuracy: 0.7470\n",
      "Epoch 4/11\n",
      "7982/7982 [==============================] - 1s 144us/step - loss: 0.8434 - accuracy: 0.8158 - val_loss: 1.0302 - val_accuracy: 0.7770\n",
      "Epoch 5/11\n",
      "7982/7982 [==============================] - 1s 147us/step - loss: 0.6669 - accuracy: 0.8568 - val_loss: 0.9559 - val_accuracy: 0.8020\n",
      "Epoch 6/11\n",
      "7982/7982 [==============================] - 1s 154us/step - loss: 0.5358 - accuracy: 0.8866 - val_loss: 0.9133 - val_accuracy: 0.8190\n",
      "Epoch 7/11\n",
      "7982/7982 [==============================] - 1s 144us/step - loss: 0.4281 - accuracy: 0.9117 - val_loss: 0.8980 - val_accuracy: 0.8080\n",
      "Epoch 8/11\n",
      "7982/7982 [==============================] - 1s 148us/step - loss: 0.3520 - accuracy: 0.9243 - val_loss: 0.8952 - val_accuracy: 0.8130\n",
      "Epoch 9/11\n",
      "7982/7982 [==============================] - 1s 145us/step - loss: 0.2871 - accuracy: 0.9369 - val_loss: 0.9319 - val_accuracy: 0.8060\n",
      "Epoch 10/11\n",
      "7982/7982 [==============================] - 1s 161us/step - loss: 0.2460 - accuracy: 0.9439 - val_loss: 0.8936 - val_accuracy: 0.8220\n",
      "Epoch 11/11\n",
      "7982/7982 [==============================] - 1s 143us/step - loss: 0.2109 - accuracy: 0.9493 - val_loss: 0.9272 - val_accuracy: 0.8180\n",
      "2246/2246 [==============================] - 0s 147us/step\n"
     ]
    }
   ],
   "source": [
    "# retarining again\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=11,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0202282774374087, 0.784060537815094]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results\n",
    "\n",
    "# slight better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/14\n",
      "7982/7982 [==============================] - 1s 155us/step - loss: 2.5720 - accuracy: 0.5180 - val_loss: 1.7317 - val_accuracy: 0.6270\n",
      "Epoch 2/14\n",
      "7982/7982 [==============================] - 1s 146us/step - loss: 1.4167 - accuracy: 0.6942 - val_loss: 1.3006 - val_accuracy: 0.7130\n",
      "Epoch 3/14\n",
      "7982/7982 [==============================] - 1s 144us/step - loss: 1.0417 - accuracy: 0.7725 - val_loss: 1.1213 - val_accuracy: 0.7510\n",
      "Epoch 4/14\n",
      "7982/7982 [==============================] - 1s 144us/step - loss: 0.8175 - accuracy: 0.8235 - val_loss: 1.0287 - val_accuracy: 0.7770\n",
      "Epoch 5/14\n",
      "7982/7982 [==============================] - 1s 155us/step - loss: 0.6532 - accuracy: 0.8582 - val_loss: 0.9764 - val_accuracy: 0.7870\n",
      "Epoch 6/14\n",
      "7982/7982 [==============================] - 1s 144us/step - loss: 0.5189 - accuracy: 0.8913 - val_loss: 0.9237 - val_accuracy: 0.8140\n",
      "Epoch 7/14\n",
      "7982/7982 [==============================] - 1s 144us/step - loss: 0.4155 - accuracy: 0.9138 - val_loss: 0.8844 - val_accuracy: 0.8100\n",
      "Epoch 8/14\n",
      "7982/7982 [==============================] - 1s 146us/step - loss: 0.3387 - accuracy: 0.9272 - val_loss: 0.9006 - val_accuracy: 0.8110\n",
      "Epoch 9/14\n",
      "7982/7982 [==============================] - 1s 146us/step - loss: 0.2795 - accuracy: 0.9397 - val_loss: 0.9004 - val_accuracy: 0.8070\n",
      "Epoch 10/14\n",
      "7982/7982 [==============================] - 1s 163us/step - loss: 0.2349 - accuracy: 0.9451 - val_loss: 0.8827 - val_accuracy: 0.8240\n",
      "Epoch 11/14\n",
      "7982/7982 [==============================] - 1s 152us/step - loss: 0.2059 - accuracy: 0.9476 - val_loss: 0.8961 - val_accuracy: 0.8170\n",
      "Epoch 12/14\n",
      "7982/7982 [==============================] - 1s 150us/step - loss: 0.1756 - accuracy: 0.9510 - val_loss: 0.9370 - val_accuracy: 0.8100\n",
      "Epoch 13/14\n",
      "7982/7982 [==============================] - 1s 140us/step - loss: 0.1625 - accuracy: 0.9541 - val_loss: 0.9555 - val_accuracy: 0.8000\n",
      "Epoch 14/14\n",
      "7982/7982 [==============================] - 1s 143us/step - loss: 0.1479 - accuracy: 0.9536 - val_loss: 0.9253 - val_accuracy: 0.8080\n",
      "2246/2246 [==============================] - 0s 164us/step\n"
     ]
    }
   ],
   "source": [
    "# retarining again \n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=14,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.091252844140451, 0.7871772050857544]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/16\n",
      "7982/7982 [==============================] - 1s 153us/step - loss: 2.6367 - accuracy: 0.4752 - val_loss: 1.7538 - val_accuracy: 0.6300\n",
      "Epoch 2/16\n",
      "7982/7982 [==============================] - 1s 144us/step - loss: 1.4492 - accuracy: 0.6880 - val_loss: 1.3227 - val_accuracy: 0.7140\n",
      "Epoch 3/16\n",
      "7982/7982 [==============================] - 1s 144us/step - loss: 1.0667 - accuracy: 0.7771 - val_loss: 1.1308 - val_accuracy: 0.7670\n",
      "Epoch 4/16\n",
      "7982/7982 [==============================] - 1s 149us/step - loss: 0.8380 - accuracy: 0.8224 - val_loss: 1.0587 - val_accuracy: 0.7650\n",
      "Epoch 5/16\n",
      "7982/7982 [==============================] - 1s 146us/step - loss: 0.6581 - accuracy: 0.8637 - val_loss: 0.9872 - val_accuracy: 0.7880\n",
      "Epoch 6/16\n",
      "7982/7982 [==============================] - 1s 147us/step - loss: 0.5274 - accuracy: 0.8921 - val_loss: 0.9047 - val_accuracy: 0.8110\n",
      "Epoch 7/16\n",
      "7982/7982 [==============================] - 1s 148us/step - loss: 0.4179 - accuracy: 0.9157 - val_loss: 0.8899 - val_accuracy: 0.8180\n",
      "Epoch 8/16\n",
      "7982/7982 [==============================] - 1s 155us/step - loss: 0.3502 - accuracy: 0.9276 - val_loss: 0.8799 - val_accuracy: 0.8220\n",
      "Epoch 9/16\n",
      "7982/7982 [==============================] - 1s 146us/step - loss: 0.2849 - accuracy: 0.9406 - val_loss: 0.8956 - val_accuracy: 0.8150\n",
      "Epoch 10/16\n",
      "7982/7982 [==============================] - 1s 147us/step - loss: 0.2412 - accuracy: 0.9456 - val_loss: 0.9493 - val_accuracy: 0.8010\n",
      "Epoch 11/16\n",
      "7982/7982 [==============================] - 1s 146us/step - loss: 0.2067 - accuracy: 0.9501 - val_loss: 0.9216 - val_accuracy: 0.8070\n",
      "Epoch 12/16\n",
      "7982/7982 [==============================] - 1s 144us/step - loss: 0.1844 - accuracy: 0.9508 - val_loss: 0.9193 - val_accuracy: 0.8160\n",
      "Epoch 13/16\n",
      "7982/7982 [==============================] - 1s 162us/step - loss: 0.1634 - accuracy: 0.9529 - val_loss: 0.9381 - val_accuracy: 0.8140\n",
      "Epoch 14/16\n",
      "7982/7982 [==============================] - 1s 157us/step - loss: 0.1524 - accuracy: 0.9541 - val_loss: 0.9746 - val_accuracy: 0.8200\n",
      "Epoch 15/16\n",
      "7982/7982 [==============================] - 1s 157us/step - loss: 0.1395 - accuracy: 0.9560 - val_loss: 0.9955 - val_accuracy: 0.8120\n",
      "Epoch 16/16\n",
      "7982/7982 [==============================] - 1s 157us/step - loss: 0.1354 - accuracy: 0.9541 - val_loss: 1.0163 - val_accuracy: 0.8040\n",
      "2246/2246 [==============================] - 0s 142us/step\n"
     ]
    }
   ],
   "source": [
    "# increasing as epochs increasing\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=16,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.121366068389091, 0.7849510312080383]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results\n",
    "\n",
    "# so trade off is between 11 < epochs < 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1834372217275156"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import copy\n",
    "\n",
    "test_labels_copy = copy.copy(test_labels)\n",
    "np.random.shuffle(test_labels_copy)\n",
    "float(np.sum(np.array(test_labels) == np.array(test_labels_copy))) / len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting for the test data // testing our model.\n",
    "\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now max value should be 1\n",
    "np.sum(predictions[0]) # this is sum of all 46 output classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0]) # class with highest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 2s 239us/step - loss: 1.7278 - accuracy: 0.6346 - val_loss: 1.1954 - val_accuracy: 0.7290\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 2s 220us/step - loss: 0.9287 - accuracy: 0.7939 - val_loss: 1.0038 - val_accuracy: 0.7840\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 2s 222us/step - loss: 0.6033 - accuracy: 0.8663 - val_loss: 0.8859 - val_accuracy: 0.8270\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 2s 223us/step - loss: 0.4017 - accuracy: 0.9142 - val_loss: 0.8666 - val_accuracy: 0.8160\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 2s 224us/step - loss: 0.2879 - accuracy: 0.9366 - val_loss: 0.9186 - val_accuracy: 0.8090\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 2s 226us/step - loss: 0.2195 - accuracy: 0.9456 - val_loss: 0.9829 - val_accuracy: 0.8040\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 2s 226us/step - loss: 0.1887 - accuracy: 0.9503 - val_loss: 0.9569 - val_accuracy: 0.8090\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 2s 242us/step - loss: 0.1654 - accuracy: 0.9529 - val_loss: 0.9980 - val_accuracy: 0.8160\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 2s 223us/step - loss: 0.1473 - accuracy: 0.9550 - val_loss: 1.0455 - val_accuracy: 0.8060\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 2s 227us/step - loss: 0.1420 - accuracy: 0.9538 - val_loss: 1.0235 - val_accuracy: 0.8040\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 2s 232us/step - loss: 0.1314 - accuracy: 0.9567 - val_loss: 1.0458 - val_accuracy: 0.8130\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 2s 224us/step - loss: 0.1241 - accuracy: 0.9572 - val_loss: 1.0896 - val_accuracy: 0.7980\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 2s 223us/step - loss: 0.1202 - accuracy: 0.9560 - val_loss: 1.1004 - val_accuracy: 0.8040\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 2s 226us/step - loss: 0.1147 - accuracy: 0.9559 - val_loss: 1.2257 - val_accuracy: 0.7970\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 2s 226us/step - loss: 0.1110 - accuracy: 0.9574 - val_loss: 1.2216 - val_accuracy: 0.7880\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 2s 229us/step - loss: 0.1057 - accuracy: 0.9565 - val_loss: 1.2975 - val_accuracy: 0.7830\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 2s 231us/step - loss: 0.1038 - accuracy: 0.9560 - val_loss: 1.2522 - val_accuracy: 0.7880\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 2s 228us/step - loss: 0.0983 - accuracy: 0.9580 - val_loss: 1.2923 - val_accuracy: 0.7920\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 2s 230us/step - loss: 0.0962 - accuracy: 0.9565 - val_loss: 1.2857 - val_accuracy: 0.7890\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 2s 228us/step - loss: 0.0941 - accuracy: 0.9558 - val_loss: 1.3655 - val_accuracy: 0.7930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x4ecf9e50>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now lets play with it \n",
    "\n",
    "# what if number of hidden units is increased or decreased ?\n",
    "\n",
    "# case 1 : increase the number of hidden units and measure accuracy\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "partial_y_train,\n",
    "epochs=20,\n",
    "batch_size=128,\n",
    "validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.121366068389091, 0.7849510312080383]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results\n",
    "\n",
    "# so accuracy is at 79.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 2s 233us/step - loss: 3.0517 - accuracy: 0.1535 - val_loss: 2.3686 - val_accuracy: 0.4110\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 2s 217us/step - loss: 1.9547 - accuracy: 0.5124 - val_loss: 1.6957 - val_accuracy: 0.6130\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 2s 220us/step - loss: 1.4804 - accuracy: 0.6477 - val_loss: 1.4878 - val_accuracy: 0.6480\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 2s 227us/step - loss: 1.3177 - accuracy: 0.6726 - val_loss: 1.4304 - val_accuracy: 0.6510\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 2s 223us/step - loss: 1.2242 - accuracy: 0.6802 - val_loss: 1.4155 - val_accuracy: 0.6490\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 2s 226us/step - loss: 1.1516 - accuracy: 0.6803 - val_loss: 1.4295 - val_accuracy: 0.6460\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 2s 223us/step - loss: 1.0861 - accuracy: 0.6832 - val_loss: 1.4048 - val_accuracy: 0.6460\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 2s 233us/step - loss: 1.0227 - accuracy: 0.6959 - val_loss: 1.4240 - val_accuracy: 0.6410\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 2s 241us/step - loss: 0.9680 - accuracy: 0.7180 - val_loss: 1.4419 - val_accuracy: 0.6560\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 2s 222us/step - loss: 0.9162 - accuracy: 0.7357 - val_loss: 1.4997 - val_accuracy: 0.6700\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 2s 223us/step - loss: 0.8712 - accuracy: 0.7456 - val_loss: 1.4973 - val_accuracy: 0.6810\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 2s 226us/step - loss: 0.8324 - accuracy: 0.7521 - val_loss: 1.5255 - val_accuracy: 0.6730\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 2s 228us/step - loss: 0.7989 - accuracy: 0.7571 - val_loss: 1.5923 - val_accuracy: 0.6730\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 2s 234us/step - loss: 0.7693 - accuracy: 0.7690 - val_loss: 1.6367 - val_accuracy: 0.6760\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 2s 222us/step - loss: 0.7442 - accuracy: 0.7835 - val_loss: 1.6839 - val_accuracy: 0.6740\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 2s 228us/step - loss: 0.7196 - accuracy: 0.7978 - val_loss: 1.7341 - val_accuracy: 0.6740\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 2s 226us/step - loss: 0.6986 - accuracy: 0.8041 - val_loss: 1.7654 - val_accuracy: 0.6780\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 2s 238us/step - loss: 0.6795 - accuracy: 0.8117 - val_loss: 1.7895 - val_accuracy: 0.6750\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 2s 234us/step - loss: 0.6614 - accuracy: 0.8167 - val_loss: 1.8696 - val_accuracy: 0.6650\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 2s 221us/step - loss: 0.6448 - accuracy: 0.8217 - val_loss: 1.9930 - val_accuracy: 0.6680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ecbf400>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# case 2 : reduce the number of hidden units \n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "partial_y_train,\n",
    "epochs=20,\n",
    "batch_size=128,\n",
    "validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  val_accuracy: 0.6680 :: so accuracy has reduced to 66 % from 79 % when\n",
    "# number of hidden units are decreased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

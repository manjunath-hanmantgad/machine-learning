{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        ],\n",
       "       [ 0.33333333],\n",
       "       [ 0.66666667],\n",
       "       [ 1.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transforming raw numerical data\n",
    "\n",
    "# recaling features. \n",
    "# preprocessing task. \n",
    "# most common is min-max scaling\n",
    "# use fit and transform or use fit_transform once.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# feature vector\n",
    "\n",
    "feature = np.array([[-500.5],\n",
    "                  [-100.1],\n",
    "                   [0],\n",
    "                   [100.1]])\n",
    "\n",
    "# create scaler\n",
    "\n",
    "#minmax_scale = preprocessing.MinMaxScaler(feature_range=(0,1)) # output #1\n",
    "\n",
    "minmax_scale = preprocessing.MinMaxScaler(feature_range=(-1,1)) # output #2\n",
    "\n",
    "# feature scaling apply\n",
    "\n",
    "scaled_feature = minmax_scale.fit_transform(feature)\n",
    "\n",
    "# dsplay feature\n",
    "\n",
    "scaled_feature\n",
    "\n",
    "\n",
    "# so all values are between 0 and 1.\n",
    "\n",
    "# now if values between -1 and 1 .. the output chnages.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.6464639 ],\n",
       "       [ 0.10976426],\n",
       "       [ 0.5488213 ],\n",
       "       [ 0.98787834]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standardizing of features\n",
    "\n",
    "# standardizing deciedded how close deviation is close to mean. ( also called as Z-score)\n",
    "# in neural network commonly used is scaling and in ML commonly used in standardizing\n",
    "# for better results use robustscaler whhich uses mean and quartile range (25th,75th)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# feature vector\n",
    "\n",
    "feature = np.array([[-500.5],\n",
    "                  [-100.1],\n",
    "                   [0],\n",
    "                   [100.1]])\n",
    "\n",
    "# create scaler \n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# feature transforming \n",
    "\n",
    "standardized = scaler.fit_transform(feature)\n",
    "\n",
    "# display feature\n",
    "\n",
    "standardized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.0\n",
      "Deviation: 1.0\n"
     ]
    }
   ],
   "source": [
    "# to print mean and standard deviation\n",
    "\n",
    "print(\"Mean:\",round(standardized.mean()))\n",
    "print(\"Deviation:\" , standardized.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.        ],\n",
       "       [-0.22222222],\n",
       "       [ 0.22222222],\n",
       "       [ 0.66666667]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use robust scaler if having outliers.\n",
    "# if there are outliers then it can affect mean and variance i.e deviation.\n",
    "\n",
    "robust_scaler = preprocessing.RobustScaler()\n",
    "\n",
    "robust_scaler.fit_transform(feature)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.],\n",
       "       [-1.],\n",
       "       [ 0.],\n",
       "       [ 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizing : rescale feature obserations to have unit norm ( sum of 1)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "features = np.array([[-500.5],\n",
    "                  [-100.1],\n",
    "                   [0],\n",
    "                   [100.1]])\n",
    "\n",
    "#normalizer = Normalizer(norm = 'l2')\n",
    "normalizer = Normalizer(norm = 'l1')\n",
    "\n",
    "normalizer.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.0050000e+02,  2.5050025e+05],\n",
       "       [-1.0010000e+02,  1.0020010e+04],\n",
       "       [ 0.0000000e+00,  0.0000000e+00],\n",
       "       [ 1.0010000e+02,  1.0020010e+04]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generating polynomial\n",
    "\n",
    "# for nonlinear relationsip between feature and targets\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "features = np.array([[-500.5],\n",
    "                  [-100.1],\n",
    "                   [0],\n",
    "                   [100.1]])\n",
    "\n",
    "# create polynomial feature object \n",
    "\n",
    "polynomial_interaction = PolynomialFeatures(degree=2 , include_bias = False) # will generate a degree =2 polynomial.\n",
    "\n",
    "# create features of polynomial\n",
    "\n",
    "polynomial_interaction.fit_transform(features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport pandas as pd\\n\\ndf = pd.DataFrame(features,columns=['feature_1','feature_2'])\\n\\ndf.apply()\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make custom transformation\n",
    "\n",
    "# using pandas is easy\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(features,columns=['feature_1','feature_2'])\n",
    "\n",
    "df.apply()\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# custom transform will make customised addition/subtraction/any operation to features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1,  1,  1,  1,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to detect outliers ?\n",
    "\n",
    "# 2 ways : \n",
    "\n",
    "# 1) using ellipticalenvelope \n",
    "# 2) using IQR based ( quartile 25th , 75th)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "features,_ = make_blobs(n_samples = 10,\n",
    "                       n_features = 2,\n",
    "                       centers= 1,\n",
    "                       random_state = 1)\n",
    "\n",
    "# now add outliers\n",
    "\n",
    "features[0,0] = 100000\n",
    "features[0,1] = 200000\n",
    "\n",
    "\n",
    "outlier_detector = EllipticEnvelope(contamination = .1)\n",
    "\n",
    "# fiting detecor\n",
    "\n",
    "outlier_detector.fit(features)\n",
    "\n",
    "# now predict outlier\n",
    "\n",
    "outlier_detector.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Bathrooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Price  Bathrooms\n",
       "0   1000          2\n",
       "1   2000          3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now how to handle outliers ?\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# create dataframe\n",
    "\n",
    "houses = pd.DataFrame()\n",
    "houses['Price'] = [1000,2000,3000]\n",
    "houses['Bathrooms'] = [2,3,500]\n",
    "\n",
    "# filter \n",
    "\n",
    "houses[houses['Bathrooms'] < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Price  Bathrooms  Outlier\n",
       "0   1000          2        0\n",
       "1   2000          3        0\n",
       "2   3000        500        1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mark as outliers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# create feature \n",
    "houses['Outlier'] = np.where(houses['Bathrooms'] < 10,0,1)\n",
    "\n",
    "houses\n",
    "\n",
    "# here outlier is shown as 1 and not outlier is shown as 0. It works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.877554</td>\n",
       "      <td>-3.336145</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-7.287210</td>\n",
       "      <td>-8.353986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6.943061</td>\n",
       "      <td>-7.023744</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7.440167</td>\n",
       "      <td>-8.791959</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.641388</td>\n",
       "      <td>-8.075888</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  group\n",
       "0  -9.877554  -3.336145      2\n",
       "1  -7.287210  -8.353986      0\n",
       "2  -6.943061  -7.023744      0\n",
       "3  -7.440167  -8.791959      0\n",
       "4  -6.641388  -8.075888      0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grouping similar observations. Also called Clustering.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "features,_ = make_blobs(n_samples=50,\n",
    "                       n_features = 2,\n",
    "                       centers = 3,\n",
    "                       random_state = 1)\n",
    "\n",
    "dataframe = pd.DataFrame(features , columns = ['feature_1','feature_2'])\n",
    "\n",
    "# K-Means cluster\n",
    "\n",
    "clusterer = KMeans(3,random_state=0)\n",
    "\n",
    "clusterer.fit(features)\n",
    "\n",
    "# predict \n",
    "\n",
    "dataframe['group'] = clusterer.predict(features)\n",
    "\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
